{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import easyocr\n",
    "\n",
    "# Crear el lector de EasyOCR para el idioma adecuado\n",
    "reader = easyocr.Reader(['en'])  \n",
    "\n",
    "root_dir = \"./datasets/matriculas-europeas\"\n",
    "subdirs = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Crear directorios de etiquetas si no existen\n",
    "for subdir in subdirs:\n",
    "    label_dir = os.path.join(root_dir, subdir, \"labels\")\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "# Función para obtener el cuadro delimitador de la matrícula usando EasyOCR\n",
    "def detectar_matricula_easyocr(imagen):\n",
    "    # Preprocesamiento de la imagen\n",
    "    imagen_gray = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    imagen_contrast = cv2.convertScaleAbs(imagen_gray, alpha=1.3, beta=15)  # Ajuste de contraste y brillo\n",
    "    resultados = reader.readtext(imagen_contrast, detail=1)\n",
    "\n",
    "    # Filtrar resultados para encontrar el texto más probable que sea una matrícula\n",
    "    for (bbox, texto, _) in resultados:\n",
    "        texto_limpio = ''.join(filter(str.isalnum, texto))  # Quitar espacios y caracteres especiales\n",
    "        if 5 <= len(texto_limpio) <= 10:  # Ajuste según longitud esperada de una matrícula\n",
    "            x_min = min(bbox[0][0], bbox[1][0], bbox[2][0], bbox[3][0])\n",
    "            y_min = min(bbox[0][1], bbox[1][1], bbox[2][1], bbox[3][1])\n",
    "            x_max = max(bbox[0][0], bbox[1][0], bbox[2][0], bbox[3][0])\n",
    "            y_max = max(bbox[0][1], bbox[1][1], bbox[2][1], bbox[3][1])\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            return x_min, y_min, width, height\n",
    "    return None  \n",
    "\n",
    "# Procesar cada conjunto de datos\n",
    "for subdir in subdirs:\n",
    "    img_dir = os.path.join(root_dir, subdir, \"images\")\n",
    "    label_dir = os.path.join(root_dir, subdir, \"labels\")\n",
    "\n",
    "    for img_path in glob.glob(f\"{img_dir}/*.[jp][pn]g\"):\n",
    "        img_name = os.path.basename(img_path).split('.')[0]\n",
    "        \n",
    "        # Leer la imagen\n",
    "        img = cv2.imread(img_path)\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        # Intentar detectar matrícula usando EasyOCR\n",
    "        ocr_box = detectar_matricula_easyocr(img)\n",
    "        \n",
    "        if ocr_box:\n",
    "            # Obtener coordenadas y dimensiones normalizadas para formato YOLO\n",
    "            x, y, w, h = ocr_box\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            width_norm = w / width\n",
    "            height_norm = h / height\n",
    "        else:\n",
    "            # Si EasyOCR no detecta, intentar una zona común para la matrícula (parte baja de la imagen)\n",
    "            print(f\"No se detectó matrícula en {img_name}. Usando zona predeterminada.\")\n",
    "            x, y = int(width * 0.2), int(height * 0.75)  # Zona estimada para la matrícula\n",
    "            w, h = int(width * 0.6), int(height * 0.2)\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            width_norm = w / width\n",
    "            height_norm = h / height\n",
    "\n",
    "        # Guardar el archivo de etiqueta en formato YOLO\n",
    "        label_file = os.path.join(label_dir, f\"{img_name}.txt\")\n",
    "        with open(label_file, 'w') as f:\n",
    "            f.write(f\"0 {x_center} {y_center} {width_norm} {height_norm}\\n\")\n",
    "\n",
    "        print(f\"Etiqueta generada para {img_name} en {label_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Verifica si se puede usar una GPU\n",
    "print(\"GPU disponible: \", torch.cuda.is_available())\n",
    "\n",
    "# Parámetros de entrenamiento para el modelo\n",
    "args = dict(\n",
    "    model=\"yolo11n.pt\",  # Modelo YOLO preentrenado\n",
    "    data=\"license_plates.yaml\",  # Archivo de configuración de datos\n",
    "    epochs=150,  # Aumentar el número de épocas\n",
    "    batch=64,  # Tamaño del lote ajustado\n",
    "    imgsz=640,  # Tamaño de imagen (ajustable según GPU)\n",
    "    multi_scale=True,  # Habilita escalado múltiple para variar el tamaño de imagen\n",
    "    workers=4,  # Número de trabajadores para el DataLoader\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Usar GPU si está disponible, de lo contrario CPU\n",
    "    verbose=True,  # Mostrar progreso de entrenamiento\n",
    "    lr0=0.001,  # Tasa de aprendizaje inicial ajustada\n",
    "    weight_decay=0.001,  # Regularización L2\n",
    "    patience=25,  # Early stopping después de 20épocas sin mejora\n",
    "    augment=True,  # Habilitar aumento de datos\n",
    ")\n",
    "\n",
    "# Inicializa el entrenador y entrena el modelo\n",
    "trainer = DetectionTrainer(overrides=args)  \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plate = YOLO('./runs/detect/train15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: SE8517BH, Probabilidad: 0.784536007570028\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "# Función para mostrar la imagen\n",
    "def mostrar_imagen(imagen):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Inicializar el lector OCR de EasyOCR\n",
    "\n",
    "def postprocesar_imagen(imagen):\n",
    "    imagen_blur = cv2.GaussianBlur( imagen.copy(), (1, 1), 0)\n",
    "    imagen_contrast = cv2.convertScaleAbs(imagen_blur, alpha=1.1, beta=15)\n",
    "    return imagen_contrast\n",
    "\n",
    "\n",
    "def detectar_texto(imagen_procesada):\n",
    "    resultado = lector.readtext(imagen_procesada, detail=1)\n",
    "    arriba_izq = (0,0)\n",
    "    abajo_der = (0,0)\n",
    "    count = 0\n",
    "    for (bbox, texto, probabilidad) in resultado:\n",
    "        # Extraer las coordenadas del bounding box\n",
    "        (arriba_izq_actual, arriba_der, abajo_der_actual, abajo_izq) = bbox\n",
    "        arriba_izq_actual = tuple([int(val) for val in arriba_izq_actual])\n",
    "        abajo_der = tuple([int(val) for val in abajo_der])\n",
    "        if (count == 0):\n",
    "            arriba_izq=arriba_izq_actual\n",
    "            abajo_der=abajo_der_actual\n",
    "            count+=1\n",
    "        else:\n",
    "            abajo_der=abajo_der_actual\n",
    "\n",
    "    if not resultado:\n",
    "        return imagen_procesada, '', 0.01\n",
    "    \n",
    "    return imagen_procesada[arriba_izq[1]:abajo_der[1], arriba_izq[0]+2:abajo_der[0]], texto, probabilidad\n",
    "\n",
    "def procesar_deteccion(imagen_procesada):\n",
    "\n",
    "    probabilidad_anterior = 0\n",
    "    imagen_actual, texto_actual, probabilidad_actual = detectar_texto(imagen_procesada)\n",
    "    \n",
    "\n",
    "    while probabilidad_actual > probabilidad_anterior:\n",
    "        probabilidad_anterior = probabilidad_actual\n",
    "        imagen_anterior = imagen_actual\n",
    "        texto_anterior = texto_actual\n",
    "        imagen_actual, texto_actual, probabilidad_actual = detectar_texto(imagen_anterior)\n",
    "\n",
    "\n",
    "    return imagen_anterior, texto_anterior, probabilidad_anterior\n",
    "\n",
    "def preprocesar_imagen(imagen):\n",
    "    imagen_blur = cv2.GaussianBlur( imagen.copy(), (5, 5), 0)\n",
    "    imagen_gray = cv2.cvtColor(imagen_blur, cv2.COLOR_BGR2GRAY)\n",
    "    imagen_contrast = cv2.convertScaleAbs(imagen_gray, alpha=1.1, beta=10)\n",
    "    _, imagen_binaria = cv2.threshold(imagen_contrast, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return imagen_binaria\n",
    "\n",
    "def procesar_imagen(imagen_procesada):\n",
    "    imagen_actual, texto_actual, probabilidad_actual = procesar_deteccion(imagen_procesada)\n",
    "    probabilidad_anterior = 0\n",
    "    imagen_anterior = ''\n",
    "    texto_anterior = ''\n",
    "    while probabilidad_actual > probabilidad_anterior:\n",
    "        probabilidad_anterior = probabilidad_actual\n",
    "        imagen_anterior = imagen_actual\n",
    "        texto_anterior = texto_actual\n",
    "        post_procesado = postprocesar_imagen(imagen_actual)\n",
    "        imagen_actual, texto_actual, probabilidad_actual = procesar_deteccion(post_procesado)\n",
    "    \n",
    "    if probabilidad_anterior > 0.01:\n",
    "        return imagen_anterior, texto_anterior, probabilidad_anterior\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def OCR(imagen):\n",
    "    imagen_preprocesada = preprocesar_imagen(imagen)\n",
    "    return procesar_imagen(imagen_preprocesada)\n",
    "\n",
    "\n",
    "lector = easyocr.Reader(['en'], gpu=False)\n",
    "image_path = 'matriculas-europeas/spanish/SE8517BW.png'\n",
    "imagen = cv2.imread(image_path)\n",
    "\n",
    "imagen, texto, probabilidad = OCR(imagen)\n",
    "\n",
    "if (not probabilidad):\n",
    "    print(\"No se detectó ninguna texto\")\n",
    "else:\n",
    "    print(f\"Resultado: {texto}, Probabilidad: {probabilidad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import easyocr\n",
    "import csv\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Configura el logger para suprimir mensajes\n",
    "logging.getLogger('ultralytics').setLevel(logging.WARNING)\n",
    "\n",
    "# Verifica si se puede usar una GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"GPU disponible: \", torch.cuda.is_available())\n",
    "\n",
    "# Configuración de OCR\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\"]\n",
    "\n",
    "# Cargar los modelos YOLO\n",
    "model_general = YOLO('yolo11n.pt')  # Modelo para detectar personas y vehículos\n",
    "model_plate = YOLO('runs/detect/train3/weights/best.pt')  # Modelo para detectar matrículas\n",
    "\n",
    "# Configuración del archivo de video y CSV\n",
    "filename = \"C0142.MP4\"\n",
    "output_video_filename = \"resultado_deteccion.mp4\"\n",
    "csv_filename = \"resultados.csv\"\n",
    "\n",
    "# Inicializar el video y el escritor\n",
    "cap = cv2.VideoCapture(filename)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out_video = cv2.VideoWriter(output_video_filename, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# Preparación del archivo CSV\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['fotograma', 'tipo_objeto', 'confianza', 'identificador_tracking', 'x1', 'y1', 'x2', 'y2',\n",
    "                         'matrícula_en_su_caso', 'texto_matricula'])\n",
    "\n",
    "    # Variables de conteo\n",
    "    conteo_clases = {name: 0 for name in classNames}\n",
    "\n",
    "    # Procesar el video con detección general\n",
    "    results = model_general.track(source=filename, show=True, stream=True, verbose=False)\n",
    "    frame_count = 0\n",
    "\n",
    "    # Almacenar matrículas y sus IDs para el seguimiento con su confianza\n",
    "    matrículas_seguimiento = {}\n",
    "\n",
    "    # Iterar sobre cada resultado por frame\n",
    "    for frame_result in results:\n",
    "        frame_count += 1\n",
    "        frame = frame_result.orig_img\n",
    "\n",
    "        # Imprimir fotograma actual y total de fotogramas\n",
    "        print(f'Procesando fotograma {frame_count}')\n",
    "\n",
    "        # Obtener detecciones y agregar track_id de cada objeto\n",
    "        for box in frame_result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            score = box.conf[0].item()\n",
    "            label = int(box.cls[0])\n",
    "            track_id = int(box.id[0]) if box.id is not None else -1\n",
    "\n",
    "            if score >= 0.4:  # Umbral de confianza\n",
    "                # Verificar si el label es válido para YOLO\n",
    "                if 0 <= label < len(classNames):\n",
    "                    label_name = classNames[label]\n",
    "\n",
    "                    # Aumentar el conteo para la clase correspondiente\n",
    "                    conteo_clases[label_name] += 1\n",
    "\n",
    "                    # Dibujar el rectángulo y mostrar el ID de seguimiento en el objeto\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "                    cv2.putText(frame, label_name, (x1, y1 - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "                    # Procesar solo si es un vehículo para buscar matrículas\n",
    "                    if label_name in [\"car\", \"bus\", \"motorbike\"]: \n",
    "                        roi = frame[y1:y2, x1:x2]  # Región de interés (ROI) del vehículo\n",
    "\n",
    "                        # Usar el modelo de matrículas para detectar matrículas en la ROI\n",
    "                        plate_results = model_plate.predict(source=roi, show=False)  \n",
    "\n",
    "                        # Procesar los resultados de detección de matrículas\n",
    "                        for plate_result in plate_results:\n",
    "                            for plate_box in plate_result.boxes:\n",
    "                                plate_x1, plate_y1, plate_x2, plate_y2 = map(int, plate_box.xyxy[0])\n",
    "                                plate_score = plate_box.conf[0].item()\n",
    "\n",
    "                                if plate_score >= 0.3:  # Umbral de confianza para matrículas\n",
    "                                    # Dibuja el rectángulo de la matrícula en el frame\n",
    "                                    cv2.rectangle(frame, (plate_x1 + x1, plate_y1 + y1), (plate_x2 + x1, plate_y2 + y1), (0, 255, 0), 2)\n",
    "\n",
    "                                    # Leer el texto de la matrícula con preprocesamiento\n",
    "                                    roi_plate = roi[plate_y1:plate_y2, plate_x1:plate_x2]\n",
    "                                    roi_plate = cv2.cvtColor(roi_plate, cv2.COLOR_BGR2GRAY)\n",
    "                                    roi_plate = cv2.equalizeHist(roi_plate)\n",
    "                                    roi_plate = cv2.adaptiveThreshold(roi_plate, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "                                    roi_plate = cv2.GaussianBlur(roi_plate, (3, 3), 0)\n",
    "\n",
    "                                    # Aplicar OCR a la ROI de la matrícula\n",
    "                                    ocr_results_plate = OCR(roi_plate)\n",
    "                                    if ocr_results_plate:\n",
    "                                        _, matricula_texto, ocr_confianza = ocr_results_plate\n",
    "                                        # Almacenar solo la matrícula con mayor confianza\n",
    "                                        if (track_id not in matrículas_seguimiento) or (ocr_confianza > matrículas_seguimiento[track_id][1]):\n",
    "                                            matrículas_seguimiento[track_id] = (matricula_texto, ocr_confianza)\n",
    "                                            print(f'Matrícula detectada en fotograma {frame_count}: {matricula_texto} con confianza {ocr_confianza}')\n",
    "\n",
    "                                    # Obtener la matrícula de mayor confianza para el CSV\n",
    "                                    texto_matricula = matrículas_seguimiento[track_id][0] if track_id in matrículas_seguimiento else \"N/A\"\n",
    "\n",
    "                                    # Escribir en el archivo CSV\n",
    "                                    csv_writer.writerow([frame_count, label_name, score, track_id, x1, y1, x2, y2,\n",
    "                                                         \"matrícula\", texto_matricula])\n",
    "\n",
    "                                    # Mostrar el texto de la matrícula en el video\n",
    "                                    cv2.putText(frame, texto_matricula, (plate_x1 + x1, plate_y1 + y1 - 10), \n",
    "                                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                                    break  # Romper después de procesar la primera matrícula detectada\n",
    "                        else:\n",
    "                            # Si no se detectó ninguna matrícula\n",
    "                            csv_writer.writerow([frame_count, label_name, score, track_id, x1, y1, x2, y2,\n",
    "                                                 \"N/A\", \"N/A\"])\n",
    "                    else:\n",
    "                        # Escribir en el archivo CSV sin matrícula para objetos que no son vehículos\n",
    "                        csv_writer.writerow([frame_count, label_name, score, track_id, x1, y1, x2, y2,\n",
    "                                             \"N/A\", \"N/A\"])\n",
    "\n",
    "                    # Mostrar la matrícula correspondiente si ya fue detectada con el texto de mayor confianza\n",
    "                    if track_id in matrículas_seguimiento:\n",
    "                        cv2.putText(frame, matrículas_seguimiento[track_id][0], (x1, y1 - 40), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Guardar el frame procesado en el archivo de video\n",
    "        out_video.write(frame)\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Mostrar conteo de clases\n",
    "print(\"Conteo total de objetos:\")\n",
    "for clase, conteo in conteo_clases.items():\n",
    "    print(f\"{clase}: {conteo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Asegurarse de que las gráficas se muestren en el notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Leer el archivo CSV de resultados\n",
    "results_csv_path = './runs/detect/train4/results.csv'\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame y las columnas disponibles\n",
    "print(results_df.head())\n",
    "print(\"Columnas disponibles:\", results_df.columns)\n",
    "\n",
    "# Verificar si las columnas necesarias existen\n",
    "required_columns = ['epoch', 'val/box_loss', 'train/box_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
    "for col in required_columns:\n",
    "    if col not in results_df.columns:\n",
    "        print(f\"Error: La columna {col} no existe en el DataFrame.\")\n",
    "        exit()\n",
    "\n",
    "# Graficar las métricas de entrenamiento y validación\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results_df['epoch'], results_df['val/box_loss'], label='Validation Box Loss')\n",
    "plt.plot(results_df['epoch'], results_df['train/box_loss'], label='Training Box Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Box Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results_df['epoch'], results_df['metrics/precision(B)'], label='Precision')\n",
    "plt.plot(results_df['epoch'], results_df['metrics/recall(B)'], label='Recall')\n",
    "plt.plot(results_df['epoch'], results_df['metrics/mAP50(B)'], label='mAP50')\n",
    "plt.plot(results_df['epoch'], results_df['metrics/mAP50-95(B)'], label='mAP50-95')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.title('Precision, Recall, and mAP Metrics')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
