{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Función para mostrar imágenes con Matplotlib\n",
    "def mostrar_imagen(imagen):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Cargar la imagen de la matrícula\n",
    "imagen_path = './matriculas-europeas/train/BY187RT.jpg'\n",
    "imagen = cv2.imread(imagen_path)\n",
    "imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "imagen_suavizada = cv2.GaussianBlur(imagen_gris, (5, 5), 0)\n",
    "imagen_contraste = cv2.convertScaleAbs(imagen_suavizada, alpha=1.5, beta=0)\n",
    "\n",
    "\n",
    "\n",
    "imagen_toCheck = imagen_contraste\n",
    "\n",
    "\n",
    "# Mostrar la imagen\n",
    "mostrar_imagen(imagen)\n",
    "mostrar_imagen(imagen_toCheck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriculas_europeas = [\n",
    "    'AL',  # Albania\n",
    "    'AND', # Andorra\n",
    "    'ARM', # Armenia\n",
    "    'A',   # Austria\n",
    "    'AZ',  # Azerbaiyán\n",
    "    'BY',  # Bielorrusia\n",
    "    'B',   # Bélgica\n",
    "    'BIH', # Bosnia y Herzegovina\n",
    "    'BG',  # Bulgaria\n",
    "    'HR',  # Croacia\n",
    "    'CY',  # Chipre\n",
    "    'CZ',  # República Checa\n",
    "    'DK',  # Dinamarca\n",
    "    'EST', # Estonia\n",
    "    'FIN', # Finlandia\n",
    "    'F',   # Francia\n",
    "    'GE',  # Georgia\n",
    "    'D',   # Alemania\n",
    "    'GR',  # Grecia\n",
    "    'H',   # Hungría\n",
    "    'IS',  # Islandia\n",
    "    'IRL', # Irlanda\n",
    "    'I',   # Italia\n",
    "    'KZ',  # Kazajistán (parte en Europa)\n",
    "    'XK',  # Kosovo\n",
    "    'LV',  # Letonia\n",
    "    'FL',  # Liechtenstein (anteriormente 'L')\n",
    "    'LT',  # Lituania\n",
    "    'L',   # Luxemburgo\n",
    "    'MK',  # Macedonia del Norte\n",
    "    'M',   # Malta\n",
    "    'MD',  # Moldavia\n",
    "    'MC',  # Mónaco\n",
    "    'ME',  # Montenegro\n",
    "    'NL',  # Países Bajos\n",
    "    'N',   # Noruega\n",
    "    'PL',  # Polonia\n",
    "    'P',   # Portugal\n",
    "    'RO',  # Rumania\n",
    "    'RUS', # Rusia\n",
    "    'SM',  # San Marino\n",
    "    'SRB', # Serbia\n",
    "    'SK',  # Eslovaquia\n",
    "    'SLO', # Eslovenia\n",
    "    'E',   # España\n",
    "    'S',   # Suecia\n",
    "    'CH',  # Suiza\n",
    "    'TR',  # Turquía\n",
    "    'UA',  # Ucrania\n",
    "    'GB',  # Reino Unido\n",
    "    'VA'   # Ciudad del Vaticano\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar el lector OCR\n",
    "lector = easyocr.Reader(['en'], gpu=False)  # Idioma en para inglés\n",
    "\n",
    "# Realizar la lectura OCR\n",
    "resultado = lector.readtext(imagen_toCheck, detail=1)\n",
    "\n",
    "img_resultado = imagen.copy()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for (bbox, texto, probabilidad) in resultado:\n",
    "    # Dibujar el cuadro delimitador alrededor del texto\n",
    "    (arriba_izq, arriba_der, abajo_der, abajo_izq) = bbox\n",
    "    arriba_izq = tuple([int(val) for val in arriba_izq])\n",
    "    abajo_der = tuple([int(val) for val in abajo_der])\n",
    "    \n",
    "    \n",
    "    if texto in matriculas_europeas:\n",
    "        cv2.rectangle(img_resultado, arriba_izq, abajo_der, (0, 255, 0), 2)\n",
    "        print(f\"País: {texto}, Probabilidad: {probabilidad}\")\n",
    "        cv2.putText(img_resultado, texto, (arriba_izq[0], arriba_izq[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    elif len(texto) >= 6 and len(texto) <= 10 and probabilidad > 0.2:\n",
    "        cv2.rectangle(img_resultado, arriba_izq, abajo_der, (0, 255, 0), 2)\n",
    "        print(f\"Matrícula: {texto}, Probabilidad: {probabilidad}\")\n",
    "\n",
    "        \n",
    "\n",
    "# Mostrar la imagen con los resultados\n",
    "mostrar_imagen(img_resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar el lector OCR\n",
    "lector = easyocr.Reader(['en'], gpu=False)  # Idioma en para inglés\n",
    "\n",
    "# Realizar la lectura OCR\n",
    "resultado = lector.readtext(imagen_toCheck, detail=1)\n",
    "\n",
    "img_resultado = imagen.copy()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for (bbox, texto, probabilidad) in resultado:\n",
    "    # Dibujar el cuadro delimitador alrededor del texto\n",
    "    (arriba_izq, arriba_der, abajo_der, abajo_izq) = bbox\n",
    "    arriba_izq = tuple([int(val) for val in arriba_izq])\n",
    "    abajo_der = tuple([int(val) for val in abajo_der])\n",
    "    \n",
    "    \n",
    "    if texto in matriculas_europeas:\n",
    "        cv2.rectangle(img_resultado, arriba_izq, abajo_der, (0, 255, 0), 2)\n",
    "        print(f\"País: {texto}, Probabilidad: {probabilidad}\")\n",
    "        cv2.putText(img_resultado, texto, (arriba_izq[0], arriba_izq[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    elif len(texto) >= 6 and len(texto) <= 10 and probabilidad > 0.2:\n",
    "        cv2.rectangle(img_resultado, arriba_izq, abajo_der, (0, 255, 0), 2)\n",
    "        print(f\"Matrícula: {texto}, Probabilidad: {probabilidad}\")\n",
    "\n",
    "        \n",
    "\n",
    "# Mostrar la imagen con los resultados\n",
    "mostrar_imagen(img_resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Función para mostrar imágenes con Matplotlib\n",
    "def mostrar_imagen(imagen):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Función para preprocesar la imagen\n",
    "def preprocesar_imagen(imagen_path):\n",
    "    imagen = cv2.imread(imagen_path)\n",
    "    imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    imagen_suavizada = cv2.GaussianBlur(imagen_gris, (5, 5), 0)\n",
    "    imagen_contraste = cv2.convertScaleAbs(imagen_suavizada, alpha=1, beta=0)\n",
    "    _, imagen_umbral = cv2.threshold(imagen_contraste, 0, 40, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return imagen_contraste\n",
    "\n",
    "# Cargar y preprocesar la imagen de la matrícula\n",
    "imagen_path = './matriculas-europeas/train/VIDEO_3_FRAME.jpg'\n",
    "imagen_preprocesada = preprocesar_imagen(imagen_path)\n",
    "\n",
    "# Mostrar la imagen original y preprocesada\n",
    "imagen_original = cv2.imread(imagen_path)\n",
    "mostrar_imagen(imagen_original)\n",
    "mostrar_imagen(imagen_preprocesada)\n",
    "\n",
    "# Inicializar el lector OCR\n",
    "lector = easyocr.Reader(['en'], gpu=True)  \n",
    "\n",
    "# Realizar la lectura OCR\n",
    "resultado = lector.readtext(imagen_preprocesada, detail=1)\n",
    "\n",
    "# Verificar la salida de resultado\n",
    "print(\"Resultado OCR:\", resultado)\n",
    "\n",
    "# Lista de matrículas europeas\n",
    "matriculas_europeas = [\n",
    "    'AL', 'AND', 'ARM', 'A', 'AZ', 'BY', 'B', 'BIH', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EST', 'FIN', 'F', 'GE', 'D', 'GR', 'H', 'IS', 'IRL', 'I', 'KZ', 'XK', 'LV', 'FL', 'LT', 'L', 'MK', 'M', 'MD', 'MC', 'ME', 'NL', 'N', 'PL', 'P', 'RO', 'RUS', 'SM', 'SRB', 'SK', 'SLO', 'E', 'S', 'CH', 'TR', 'UA', 'GB', 'VA'\n",
    "]\n",
    "\n",
    "img_resultado = imagen_original.copy()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for (bbox, texto, probabilidad) in resultado:\n",
    "    (arriba_izq, arriba_der, abajo_der, abajo_izq) = bbox\n",
    "    arriba_izq = tuple([int(val) for val in arriba_izq])\n",
    "    abajo_der = tuple([int(val) for val in abajo_der])\n",
    "    \n",
    "    print(f\"Texto detectado: {texto}, Probabilidad: {probabilidad}, Coordenadas: {bbox}\")\n",
    "    \n",
    "    # Ajustar las condiciones para dibujar el cuadro delimitador\n",
    "    if probabilidad > 0.5 and (texto in matriculas_europeas or (len(texto) >= 6 and len(texto) <= 10)):\n",
    "        cv2.rectangle(img_resultado, arriba_izq, abajo_der, (0, 255, 0), 2)\n",
    "        cv2.putText(img_resultado, texto, (arriba_izq[0], arriba_izq[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        print(f\"Texto: {texto}, Probabilidad: {probabilidad}\")\n",
    "\n",
    "# Mostrar la imagen con los resultados\n",
    "mostrar_imagen(img_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, root, subset='train', transforms=None):\n",
    "        self.root = os.path.join(root, subset)\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(self.root)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = os.path.splitext(self.imgs[idx])[0]  # El nombre del archivo sin la extensión es la etiqueta\n",
    "        boxes = []  # Aquí puedes agregar lógica para obtener las cajas delimitadoras si las tienes\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": image_id, \"area\": area, \"iscrowd\": iscrowd, \"label\": label}\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(torchvision.transforms.RandomHorizontalFlip(0.5))\n",
    "    return torchvision.transforms.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1/296, Loss: 1.135436773300171, Image: 2\n",
      "Epoch 1, Batch 2/296, Loss: 0.40122875571250916, Image: 4\n",
      "Epoch 1, Batch 3/296, Loss: 0.3070296049118042, Image: 6\n",
      "Epoch 1, Batch 4/296, Loss: 0.318372517824173, Image: 8\n",
      "Epoch 1, Batch 5/296, Loss: 0.36659783124923706, Image: 10\n",
      "Epoch 1, Batch 6/296, Loss: 0.26940804719924927, Image: 12\n",
      "Epoch 1, Batch 7/296, Loss: 0.4118106961250305, Image: 14\n",
      "Epoch 1, Batch 8/296, Loss: 0.29648271203041077, Image: 16\n",
      "Epoch 1, Batch 9/296, Loss: 0.4406740963459015, Image: 18\n",
      "Epoch 1, Batch 10/296, Loss: 0.2615220546722412, Image: 20\n",
      "Epoch 1, Batch 11/296, Loss: 0.3029644191265106, Image: 22\n",
      "Epoch 1, Batch 12/296, Loss: 0.3136722147464752, Image: 24\n",
      "Epoch 1, Batch 13/296, Loss: 0.28463613986968994, Image: 26\n",
      "Epoch 1, Batch 14/296, Loss: 0.2795834243297577, Image: 28\n",
      "Epoch 1, Batch 15/296, Loss: 0.3339408338069916, Image: 30\n",
      "Epoch 1, Batch 16/296, Loss: 0.2748472988605499, Image: 32\n",
      "Epoch 1, Batch 17/296, Loss: 0.24564848840236664, Image: 34\n",
      "Epoch 1, Batch 18/296, Loss: 0.39598286151885986, Image: 36\n",
      "Epoch 1, Batch 19/296, Loss: 0.27847686409950256, Image: 38\n",
      "Epoch 1, Batch 20/296, Loss: 0.32156574726104736, Image: 40\n",
      "Epoch 1, Batch 21/296, Loss: 0.31333303451538086, Image: 42\n",
      "Epoch 1, Batch 22/296, Loss: 0.2950749695301056, Image: 44\n",
      "Epoch 1, Batch 23/296, Loss: 0.27834194898605347, Image: 46\n",
      "Epoch 1, Batch 24/296, Loss: 0.3099316656589508, Image: 48\n",
      "Epoch 1, Batch 25/296, Loss: 0.2756578028202057, Image: 50\n",
      "Epoch 1, Batch 26/296, Loss: 0.35503271222114563, Image: 52\n",
      "Epoch 1, Batch 27/296, Loss: 0.29494214057922363, Image: 54\n",
      "Epoch 1, Batch 28/296, Loss: 0.24901483952999115, Image: 56\n",
      "Epoch 1, Batch 29/296, Loss: 0.2597576677799225, Image: 58\n",
      "Epoch 1, Batch 30/296, Loss: 0.19233505427837372, Image: 60\n",
      "Epoch 1, Batch 31/296, Loss: 0.270940899848938, Image: 62\n",
      "Epoch 1, Batch 32/296, Loss: 0.21288657188415527, Image: 64\n",
      "Epoch 1, Batch 33/296, Loss: 0.2652791142463684, Image: 66\n",
      "Epoch 1, Batch 34/296, Loss: 0.30993059277534485, Image: 68\n",
      "Epoch 1, Batch 35/296, Loss: 0.2704920470714569, Image: 70\n",
      "Epoch 1, Batch 36/296, Loss: 0.25571003556251526, Image: 72\n",
      "Epoch 1, Batch 37/296, Loss: 0.2416386902332306, Image: 74\n",
      "Epoch 1, Batch 38/296, Loss: 0.22407843172550201, Image: 76\n",
      "Epoch 1, Batch 39/296, Loss: 0.19093534350395203, Image: 78\n",
      "Epoch 1, Batch 40/296, Loss: 0.3421514332294464, Image: 80\n",
      "Epoch 1, Batch 41/296, Loss: 0.22488832473754883, Image: 82\n",
      "Epoch 1, Batch 42/296, Loss: 0.22125361859798431, Image: 84\n",
      "Epoch 1, Batch 43/296, Loss: 0.2326200306415558, Image: 86\n",
      "Epoch 1, Batch 44/296, Loss: 0.22231923043727875, Image: 88\n",
      "Epoch 1, Batch 45/296, Loss: 0.19511070847511292, Image: 90\n",
      "Epoch 1, Batch 46/296, Loss: 0.2371988594532013, Image: 92\n",
      "Epoch 1, Batch 47/296, Loss: 0.2260059267282486, Image: 94\n",
      "Epoch 1, Batch 48/296, Loss: 0.20650193095207214, Image: 96\n",
      "Epoch 1, Batch 49/296, Loss: 0.25350528955459595, Image: 98\n",
      "Epoch 1, Batch 50/296, Loss: 0.15422354638576508, Image: 100\n",
      "Epoch 1, Batch 51/296, Loss: 0.2338627129793167, Image: 102\n",
      "Epoch 1, Batch 52/296, Loss: 0.26949751377105713, Image: 104\n",
      "Epoch 1, Batch 53/296, Loss: 0.2234976440668106, Image: 106\n",
      "Epoch 1, Batch 54/296, Loss: 0.22918489575386047, Image: 108\n",
      "Epoch 1, Batch 55/296, Loss: 0.23492905497550964, Image: 110\n",
      "Epoch 1, Batch 56/296, Loss: 0.16723689436912537, Image: 112\n",
      "Epoch 1, Batch 57/296, Loss: 0.20847077667713165, Image: 114\n",
      "Epoch 1, Batch 58/296, Loss: 0.21238769590854645, Image: 116\n",
      "Epoch 1, Batch 59/296, Loss: 0.2713911831378937, Image: 118\n",
      "Epoch 1, Batch 60/296, Loss: 0.15144029259681702, Image: 120\n",
      "Epoch 1, Batch 61/296, Loss: 0.2647630572319031, Image: 122\n",
      "Epoch 1, Batch 62/296, Loss: 0.26115766167640686, Image: 124\n",
      "Epoch 1, Batch 63/296, Loss: 0.24771717190742493, Image: 126\n",
      "Epoch 1, Batch 64/296, Loss: 0.3472938537597656, Image: 128\n",
      "Epoch 1, Batch 65/296, Loss: 0.17776092886924744, Image: 130\n",
      "Epoch 1, Batch 66/296, Loss: 0.216611847281456, Image: 132\n",
      "Epoch 1, Batch 67/296, Loss: 0.21317477524280548, Image: 134\n",
      "Epoch 1, Batch 68/296, Loss: 0.19205470383167267, Image: 136\n",
      "Epoch 1, Batch 69/296, Loss: 0.1755322515964508, Image: 138\n",
      "Epoch 1, Batch 70/296, Loss: 0.1668771356344223, Image: 140\n",
      "Epoch 1, Batch 71/296, Loss: 0.24788598716259003, Image: 142\n",
      "Epoch 1, Batch 72/296, Loss: 0.18326245248317719, Image: 144\n",
      "Epoch 1, Batch 73/296, Loss: 0.2114258110523224, Image: 146\n",
      "Epoch 1, Batch 74/296, Loss: 0.2296076864004135, Image: 148\n",
      "Epoch 1, Batch 75/296, Loss: 0.25000423192977905, Image: 150\n",
      "Epoch 1, Batch 76/296, Loss: 0.1772768199443817, Image: 152\n",
      "Epoch 1, Batch 77/296, Loss: 0.18582826852798462, Image: 154\n",
      "Epoch 1, Batch 78/296, Loss: 0.18947581946849823, Image: 156\n",
      "Epoch 1, Batch 79/296, Loss: 0.18884111940860748, Image: 158\n",
      "Epoch 1, Batch 80/296, Loss: 0.12876412272453308, Image: 160\n",
      "Epoch 1, Batch 81/296, Loss: 0.18660731613636017, Image: 162\n",
      "Epoch 1, Batch 82/296, Loss: 0.14772433042526245, Image: 164\n",
      "Epoch 1, Batch 83/296, Loss: 0.16759954392910004, Image: 166\n",
      "Epoch 1, Batch 84/296, Loss: 0.16402386128902435, Image: 168\n",
      "Epoch 1, Batch 85/296, Loss: 0.14056949317455292, Image: 170\n",
      "Epoch 1, Batch 86/296, Loss: 0.17470085620880127, Image: 172\n",
      "Epoch 1, Batch 87/296, Loss: 0.22937850654125214, Image: 174\n",
      "Epoch 1, Batch 88/296, Loss: 0.2021685242652893, Image: 176\n",
      "Epoch 1, Batch 89/296, Loss: 0.19332285225391388, Image: 178\n",
      "Epoch 1, Batch 90/296, Loss: 0.24855874478816986, Image: 180\n",
      "Epoch 1, Batch 91/296, Loss: 0.18731139600276947, Image: 182\n",
      "Epoch 1, Batch 92/296, Loss: 0.22708243131637573, Image: 184\n",
      "Epoch 1, Batch 93/296, Loss: 0.18036776781082153, Image: 186\n",
      "Epoch 1, Batch 94/296, Loss: 0.156652569770813, Image: 188\n",
      "Epoch 1, Batch 95/296, Loss: 0.21905680000782013, Image: 190\n",
      "Epoch 1, Batch 96/296, Loss: 0.18705390393733978, Image: 192\n",
      "Epoch 1, Batch 97/296, Loss: 0.17571163177490234, Image: 194\n",
      "Epoch 1, Batch 98/296, Loss: 0.2077196091413498, Image: 196\n",
      "Epoch 1, Batch 99/296, Loss: 0.18071511387825012, Image: 198\n",
      "Epoch 1, Batch 100/296, Loss: 0.19463928043842316, Image: 200\n",
      "Epoch 1, Batch 101/296, Loss: 0.22199763357639313, Image: 202\n",
      "Epoch 1, Batch 102/296, Loss: 0.14972533285617828, Image: 204\n",
      "Epoch 1, Batch 103/296, Loss: 0.24555332958698273, Image: 206\n",
      "Epoch 1, Batch 104/296, Loss: 0.2013571858406067, Image: 208\n",
      "Epoch 1, Batch 105/296, Loss: 0.1422979086637497, Image: 210\n",
      "Epoch 1, Batch 106/296, Loss: 0.1878221035003662, Image: 212\n",
      "Epoch 1, Batch 107/296, Loss: 0.18541808426380157, Image: 214\n",
      "Epoch 1, Batch 108/296, Loss: 0.1816529929637909, Image: 216\n",
      "Epoch 1, Batch 109/296, Loss: 0.22049589455127716, Image: 218\n",
      "Epoch 1, Batch 110/296, Loss: 0.19749628007411957, Image: 220\n",
      "Epoch 1, Batch 111/296, Loss: 0.2301567941904068, Image: 222\n",
      "Epoch 1, Batch 112/296, Loss: 0.2048717886209488, Image: 224\n",
      "Epoch 1, Batch 113/296, Loss: 0.13148494064807892, Image: 226\n",
      "Epoch 1, Batch 114/296, Loss: 0.29719609022140503, Image: 228\n",
      "Epoch 1, Batch 115/296, Loss: 0.129120334982872, Image: 230\n",
      "Epoch 1, Batch 116/296, Loss: 0.15800856053829193, Image: 232\n",
      "Epoch 1, Batch 117/296, Loss: 0.16930018365383148, Image: 234\n",
      "Epoch 1, Batch 118/296, Loss: 0.22328491508960724, Image: 236\n",
      "Epoch 1, Batch 119/296, Loss: 0.1506233662366867, Image: 238\n",
      "Epoch 1, Batch 120/296, Loss: 0.16966959834098816, Image: 240\n",
      "Epoch 1, Batch 121/296, Loss: 0.16484665870666504, Image: 242\n",
      "Epoch 1, Batch 122/296, Loss: 0.15054430067539215, Image: 244\n",
      "Epoch 1, Batch 123/296, Loss: 0.18890266120433807, Image: 246\n",
      "Epoch 1, Batch 124/296, Loss: 0.20341865718364716, Image: 248\n",
      "Epoch 1, Batch 125/296, Loss: 0.20709411799907684, Image: 250\n",
      "Epoch 1, Batch 126/296, Loss: 0.1965358853340149, Image: 252\n",
      "Epoch 1, Batch 127/296, Loss: 0.14554648101329803, Image: 254\n",
      "Epoch 1, Batch 128/296, Loss: 0.13013353943824768, Image: 256\n",
      "Epoch 1, Batch 129/296, Loss: 0.15927544236183167, Image: 258\n",
      "Epoch 1, Batch 130/296, Loss: 0.11795275658369064, Image: 260\n",
      "Epoch 1, Batch 131/296, Loss: 0.16743966937065125, Image: 262\n",
      "Epoch 1, Batch 132/296, Loss: 0.27262768149375916, Image: 264\n",
      "Epoch 1, Batch 133/296, Loss: 0.15975823998451233, Image: 266\n",
      "Epoch 1, Batch 134/296, Loss: 0.1362093985080719, Image: 268\n",
      "Epoch 1, Batch 135/296, Loss: 0.16077588498592377, Image: 270\n",
      "Epoch 1, Batch 136/296, Loss: 0.16284334659576416, Image: 272\n",
      "Epoch 1, Batch 137/296, Loss: 0.1525786817073822, Image: 274\n",
      "Epoch 1, Batch 138/296, Loss: 0.1416338086128235, Image: 276\n",
      "Epoch 1, Batch 139/296, Loss: 0.1381615549325943, Image: 278\n",
      "Epoch 1, Batch 140/296, Loss: 0.1910417377948761, Image: 280\n",
      "Epoch 1, Batch 141/296, Loss: 0.1258808970451355, Image: 282\n",
      "Epoch 1, Batch 142/296, Loss: 0.12924718856811523, Image: 284\n",
      "Epoch 1, Batch 143/296, Loss: 0.17590810358524323, Image: 286\n",
      "Epoch 1, Batch 144/296, Loss: 0.22879403829574585, Image: 288\n",
      "Epoch 1, Batch 145/296, Loss: 0.11846140027046204, Image: 290\n",
      "Epoch 1, Batch 146/296, Loss: 0.1416403353214264, Image: 292\n",
      "Epoch 1, Batch 147/296, Loss: 0.22740438580513, Image: 294\n",
      "Epoch 1, Batch 148/296, Loss: 0.23138394951820374, Image: 296\n",
      "Epoch 1, Batch 149/296, Loss: 0.2439003884792328, Image: 298\n",
      "Epoch 1, Batch 150/296, Loss: 0.24999511241912842, Image: 300\n",
      "Epoch 1, Batch 151/296, Loss: 0.2186102271080017, Image: 302\n",
      "Epoch 1, Batch 152/296, Loss: 0.24216720461845398, Image: 304\n",
      "Epoch 1, Batch 153/296, Loss: 0.23857510089874268, Image: 306\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Preparar el dataset y el dataloader\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class LicensePlateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, subset, transforms=None):\n",
    "        self.root = root\n",
    "        self.subset = subset\n",
    "        self.transforms = transforms\n",
    "        # Load all image files, sorting them to ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, subset))))\n",
    "        self.boxes = self.load_boxes()  # Load the bounding boxes\n",
    "\n",
    "    def load_boxes(self):\n",
    "        # Implement this method to load bounding boxes\n",
    "        # For now, let's assume it returns a list of tensors\n",
    "        boxes = []\n",
    "        for img in self.imgs:\n",
    "            # Dummy bounding box for debugging\n",
    "            boxes.append(torch.tensor([[0, 0, 10, 10]], dtype=torch.float32))\n",
    "        return boxes\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images and bounding boxes\n",
    "        img_path = os.path.join(self.root, self.subset, self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        box = self.boxes[idx]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, box = self.transforms(img, box)\n",
    "        else:\n",
    "            img = T.ToTensor()(img)\n",
    "\n",
    "        # Label for license plate\n",
    "        label = torch.tensor([1], dtype=torch.int64)\n",
    "\n",
    "        return img, {\"boxes\": box, \"labels\": label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "dataset = LicensePlateDataset('./matriculas-europeas', subset='train', transforms=None)\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Definir el modelo\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2  # 1 class (license plate) + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Definir el optimizador y el scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Entrenar el modelo\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_images = 0\n",
    "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += losses.item()\n",
    "        total_images += len(images)\n",
    "        \n",
    "        # Print the progress within the epoch\n",
    "        print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(data_loader)}, Loss: {losses.item()}, Image: {total_images}\")\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Total Loss: {epoch_loss}, Total Images: {total_images}\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'license_plate_detector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from collections import defaultdict\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Cargar el modelo de detección de vehículos\n",
    "model_vehiculos = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_vehiculos.eval()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_vehiculos.to(device)\n",
    "\n",
    "# Cargar el modelo de detección de matrículas\n",
    "model_matriculas = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "num_classes = 2  # 1 class (license plate) + background\n",
    "in_features = model_matriculas.roi_heads.box_predictor.cls_score.in_features\n",
    "model_matriculas.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "model_matriculas.load_state_dict(torch.load('license_plate_detector.pth'))\n",
    "model_matriculas.eval()\n",
    "model_matriculas.to(device)\n",
    "\n",
    "# Configuración del OCR\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "# Etiquetas de las clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "# Función para anonimizar personas y vehículos\n",
    "def anonymize_image(image, boxes):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        image[y1:y2, x1:x2] = cv2.GaussianBlur(image[y1:y2, x1:x2], (99, 99), 30)\n",
    "    return image\n",
    "\n",
    "# Función para determinar el flujo de personas y vehículos\n",
    "def determine_flow(track_history, current_frame):\n",
    "    flow = {\"left\": 0, \"right\": 0, \"up\": 0, \"down\": 0}\n",
    "    for track_id, track in track_history.items():\n",
    "        if len(track) > 1:\n",
    "            x1, y1 = track[-2]\n",
    "            x2, y2 = track[-1]\n",
    "            if x2 < x1:\n",
    "                flow[\"left\"] += 1\n",
    "            elif x2 > x1:\n",
    "                flow[\"right\"] += 1\n",
    "            if y2 < y1:\n",
    "                flow[\"up\"] += 1\n",
    "            elif y2 > y1:\n",
    "                flow[\"down\"] += 1\n",
    "    return flow\n",
    "\n",
    "# Captura desde el video\n",
    "filename = \"C0142.MP4\"\n",
    "\n",
    "# Inicializar el historial de seguimiento\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Inicializar el archivo CSV\n",
    "csv_file = open('resultados.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['fotograma', 'tipo_objeto', 'confianza', 'identificador_tracking', 'x1', 'y1', 'x2', 'y2', 'matrícula_en_su_caso', 'confianza_matricula', 'mx1', 'my1', 'mx2', 'my2', 'texto_matricula'])\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# Inicializar el VideoWriter\n",
    "cap = cv2.VideoCapture(filename)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('resultado.avi', fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Procesar el video y mostrar resultados en tiempo real\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    print(f'Procesando frame {frame_count}')\n",
    "\n",
    "    # Convertir el frame a tensor y moverlo al dispositivo\n",
    "    frame_tensor = F.to_tensor(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # Detectar vehículos en el frame\n",
    "    with torch.no_grad():\n",
    "        detections_vehiculos = model_vehiculos(frame_tensor)[0]\n",
    "\n",
    "    # Procesar resultados de detección de vehículos\n",
    "    for i in range(len(detections_vehiculos['boxes'])):\n",
    "        x1, y1, x2, y2 = map(int, detections_vehiculos['boxes'][i].tolist())\n",
    "        score = detections_vehiculos['scores'][i].item()\n",
    "        label = detections_vehiculos['labels'][i].item()\n",
    "        if score >= 0.5 and label in [3, 4, 6, 8]:  # Umbral de confianza y etiquetas de vehículos\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Convertir el ROI a tensor y moverlo al dispositivo\n",
    "            roi_tensor = F.to_tensor(roi).unsqueeze(0).to(device)\n",
    "\n",
    "            # Detectar matrículas en el ROI\n",
    "            with torch.no_grad():\n",
    "                detections_matriculas = model_matriculas(roi_tensor)[0]\n",
    "\n",
    "            # Procesar resultados de detección de matrículas\n",
    "            for j in range(len(detections_matriculas['boxes'])):\n",
    "                mx1, my1, mx2, my2 = map(int, detections_matriculas['boxes'][j].tolist())\n",
    "                mscore = detections_matriculas['scores'][j].item()\n",
    "                if mscore >= 0.5:  # Umbral de confianza\n",
    "                    cv2.rectangle(frame, (x1 + mx1, y1 + my1), (x1 + mx2, y1 + my2), (0, 255, 0), 2)\n",
    "                    mroi = frame[y1 + my1:y1 + my2, x1 + mx1:x1 + mx2]\n",
    "                    ocr_results = reader.readtext(mroi)\n",
    "                    for (bbox, text, prob) in ocr_results:\n",
    "                        (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "                        tx1, ty1 = map(int, top_left)\n",
    "                        tx2, ty2 = map(int, bottom_right)\n",
    "                        cv2.rectangle(frame, (x1 + mx1 + tx1, y1 + my1 + ty1), (x1 + mx1 + tx2, y1 + my1 + ty2), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, text, (x1 + mx1 + tx1, y1 + my1 + ty1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                        csv_writer.writerow([frame_count, 'license_plate', mscore, '', x1 + mx1, y1 + my1, x1 + mx2, y1 + my2, text, prob, x1 + mx1 + tx1, y1 + my1 + ty1, x1 + mx1 + tx2, y1 + my1 + ty2, text])\n",
    "\n",
    "    # Write the processed frame to the video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Mostrar el frame procesado en una ventana\n",
    "    cv2.imshow('Resultado', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Determinar el flujo de personas y vehículos\n",
    "    flow = determine_flow(track_history, frame_count)\n",
    "    print(f'Flujo en el fotograma {frame_count}: {flow}')\n",
    "\n",
    "# Liberar recursos\n",
    "csv_file.close()\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducir el video\n",
    "cap = cv2.VideoCapture('resultado.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Resultado', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
