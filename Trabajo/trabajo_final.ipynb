{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from queue import Queue\n",
    "import threading\n",
    "from lib.Models import Models\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = [\"dog\", \"cow\"] # Nombres de las clases a detectar con yolo\n",
    "dog_info = {}\n",
    "\n",
    "model_general = YOLO('yolo11n.pt')  # Modelo para detectar personas y vehículos\n",
    "models = Models(dog_info)  # Modelos para el procesamiento de los caracteristicas\n",
    "\n",
    "filename = \"video_dogs.mp4\" # Video a procesar\n",
    "output_video_filename = \"resultado_deteccion.mp4\" #Video con la detección y el procesado\n",
    "\n",
    "intel_dog_data_csv_filename = \"dog_intelligence.csv\" # Archivo con la información de la inteligencia promedio de los perros en base a la raza\n",
    "size_dog_data_csv_filename = \"AKC_Breed_info.csv\" # Archivo con la información del tamaño promedio de los perros en base a la raza\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_number = 1\n",
    "\n",
    "\n",
    "id_buffer = Queue()\n",
    "\n",
    "pause_event = threading.Event()\n",
    "\n",
    "#semaphore = threading.Semaphore(4)\n",
    "\n",
    "pause_event.clear()\n",
    "\n",
    "\n",
    "def frame_to_characteristics():\n",
    "    while True:\n",
    "        \n",
    "        track_id, score = id_buffer.get()\n",
    "        \n",
    "        if track_id is None: pause_event.wait()\n",
    "\n",
    "        pause_event.clear()\n",
    "        threading.Thread(target=models.set_characteristics, args=(track_id,)).start()\n",
    "        print(f\"ID: {track_id}, Score: {score}\")\n",
    "        \n",
    "\n",
    "characteristics_thread = threading.Thread(target=frame_to_characteristics)\n",
    "characteristics_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2, Score: 0.7943414449691772\n",
      "ID: 2, Score: 0.8188602924346924\n",
      "ID: 1, Score: 0.7355778813362122\n",
      "ID: 2, Score: 0.8634712100028992\n",
      "ID: 4, Score: 0.82431560754776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = model_general.track(source=filename, stream=True, verbose=False)\n",
    "frame_count = 0\n",
    "\n",
    "def set_track_id(frame):\n",
    "    list_characteristics = dog_info.get(track_id, [frame, score, \" \", \" \", \" \", 0])\n",
    "    list_characteristics[0] = frame\n",
    "    list_characteristics[1] = score\n",
    "    dog_info[track_id] = list_characteristics\n",
    "\n",
    "for frame_result in results:\n",
    "    frame_count += 1\n",
    "    frame = frame_result.orig_img\n",
    "    time.sleep(0.05)\n",
    "\n",
    "    # Imprimir fotograma actual y total de fotogramas\n",
    "    #print(f'Procesando fotograma {frame_count}')\n",
    "    \n",
    "    for box in frame_result.boxes:\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        score = box.conf[0].item()\n",
    "        label = int(box.cls[0])\n",
    "        track_id = int(box.id[0]) if box.id is not None else -1\n",
    "        \n",
    "        #Validación de label  dog = 16  y  Umbral de confianza\n",
    "        if score>0.6 and label==16 : \n",
    "            if (dog_info.get(track_id, [0, 0, \"\", \"\", \"\", \"\"])[1] < score):                \n",
    "                id_buffer.put([track_id, score])\n",
    "                pause_event.set()\n",
    "                set_track_id(frame[x1:x2, y1:y2])\n",
    "\n",
    "        \n",
    "        if track_id in dog_info:\n",
    "            cv2.rectangle(frame, (x1,  y1), (x2, y2), (0, 255, 0), 2)\n",
    "            #cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "            cv2.putText(frame,  f\"Breed: {dog_info[track_id][3]}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.putText(frame,  f\"Color: {dog_info[track_id][2]} Emotion: {dog_info[track_id][4]}\", (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.putText(frame,  f\"Count: {dog_info[track_id][5]}\", (x1, y1 - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow('Detección en proceso', frame)\n",
    "\n",
    "    # Esperar brevemente para permitir visualización, y detener si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc_trabajo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
